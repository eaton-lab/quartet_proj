{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares quartet inference on simulated data by a softmax regression machine learning model to that by SVDquartets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import re\n",
    "import random\n",
    "from itertools import compress\n",
    "import itertools\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "from Bio import Phylo\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "Reads in sequence data generated on a phylogeny, along with the phylogeny. \n",
    "\n",
    "Returns a sequence matrix split on t1, t2 | t3, t4, as well as a three-element array of what the real split is in the tree. \n",
    "\n",
    "To define the real split on the tree:\n",
    "\n",
    "[1, 0, 0] = t1, t2 | t3, t4\n",
    "\n",
    "[0, 1, 0] = t1, t3 | t2, t4\n",
    "\n",
    "[0, 0, 1] = t1, t4 | t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_quint_pred_actual(sequencedata, phylogeny):\n",
    "    # read in data\n",
    "\n",
    "    fname = sequencedata\n",
    "    with open(fname) as f:\n",
    "        sequences = f.readlines()\n",
    "\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "\n",
    "    sequences = [x.strip() for x in sequences] \n",
    "    sequences.pop(0)\n",
    "\n",
    "    # get sequences  and identify quintet taxa\n",
    "    names = [sequences[i][0:10].strip(\" \") for i in range(len(sequences))]\n",
    "    iso_sequences = [sequences[i][10:].strip(\" \") for i in range(len(sequences))]\n",
    "    \n",
    "    # so we're only testing one possible quartet per tree... Easy to expand this to test every quintet per tree\n",
    "    interestednames = [\"t1\",\"t2\",\"t3\",\"t4\"]\n",
    "    taxa_ids = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in interestednames]]))\n",
    "    \n",
    "    #taxa_ids = [3,2,8,9]\n",
    "    #fourtaxa = [names[i] for i in taxa_ids]\n",
    "\n",
    "    tempobj = [iso_sequences[i] for i in taxa_ids]\n",
    "\n",
    "    # eliminate non-snps\n",
    "\n",
    "    ind_samples = []\n",
    "    for i in range(len(tempobj[0])):\n",
    "        currentbase = ([tempobj[q][i] for q in range(len(tempobj))])\n",
    "        if (len(set(currentbase)) > 1):\n",
    "            ind_samples.append(currentbase)\n",
    "    ind_samples_reset = ind_samples\n",
    "\n",
    "    # separate sequences by fifth taxon\n",
    "\n",
    "    ind_samples = np.array(ind_samples_reset)\n",
    "    ind_samples = np.where(ind_samples=='A',0,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='C',1,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='G',2,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='T',3,ind_samples)\n",
    "    ind_samples = ind_samples.astype(int)\n",
    "\n",
    "    # get the matrices\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "    # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    arr0123 = ind_samples\n",
    "    for i in range(len(arr0123)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[arr0123[i][0],arr0123[i][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[arr0123[i][2],arr0123[i][3]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "    #allmats.append(fullmat0123)\n",
    "\n",
    "    # predict the true quintet\n",
    "\n",
    "    # compare with actual quintet\n",
    "\n",
    "    tree = Phylo.read(phylogeny, 'newick')\n",
    "\n",
    "    tipnames = [names[i] for i in taxa_ids]\n",
    "    indexing = np.array([[0,1],[0,2],[0,3],[1,2],[1,3],[2,3]])\n",
    "\n",
    "    alldists = [tree.distance(tipnames[0],tipnames[1]),\n",
    "                tree.distance(tipnames[0],tipnames[2]),\n",
    "                tree.distance(tipnames[0],tipnames[3]),\n",
    "                tree.distance(tipnames[1],tipnames[2]),\n",
    "                tree.distance(tipnames[1],tipnames[3]),\n",
    "                tree.distance(tipnames[2],tipnames[3])]\n",
    "\n",
    "    min_tree_pairs1, min_pair_val1 = min(enumerate(alldists), key=itemgetter(1))\n",
    "    \n",
    "    paired_taxa =  [tipnames[i] for i in list(indexing[min_tree_pairs1])] + [tipnames[i] for i in list(set([0,1,2,3]) ^ set(list(indexing[min_tree_pairs1])))]\n",
    "    quartet_numbers = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in paired_taxa]]))\n",
    "    \n",
    "    # is this a 0123, 0213, or 0312?\n",
    "    correct_config = np.array([(set([taxa_ids[i] for i in [0,1,2,3]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,1,2,3]][2:4]) == set(quartet_numbers[0:2])),\n",
    "                                (set([taxa_ids[i] for i in [0,2,1,3]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,2,1,3]][2:4]) == set(quartet_numbers[0:2])),\n",
    "                                (set([taxa_ids[i] for i in [0,3,1,2]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,3,1,2]][2:4]) == set(quartet_numbers[0:2]))]).astype(int)\n",
    "    \n",
    "    return(taxa_ids,quartet_numbers,paired_taxa,correct_config,fullmat0123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the function to all of our tree/sequence combinations, saving the sequence matrices as `images` and the true splits as `labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(2001)[1:2001]:\n",
    "    test = compare_quint_pred_actual(sequencedata=\"tree_seqs/test\" + str(i) + \".dat\",phylogeny=\"random_trees/samp\" + str(i) + \".phy\")\n",
    "    images.append(test[4].flatten()/max(test[4].flatten()))\n",
    "    labels.append(test[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run a very simple (as in, from the tensorflow tutorial) softmax regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985986\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 256])\n",
    "W = tf.Variable(tf.zeros([256, 3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for _ in range(1000):\n",
    "  batch = np.random.choice(1000, 50)\n",
    "  batch_xs, batch_ys = np.array([images[i] for i in batch]),np.array([labels[i] for i in batch])\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: images[1001:2000], y_: labels[1001:2000]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows 98.6% successful prediction of quartet arrangements by our simple machine learning model.\n",
    "\n",
    "This high rate is easy to accomplish because the seq-gen settings are really basic, and we have lots of loci to work with. With real data, we'd want more sophisticated models and would still probably end up with lower rates of success. Model training relies on simulated sequence data, so making the jump to empirical data might be hard. We'd need a way to test robustness of the model to variation in data. \n",
    "\n",
    "Many of the branch lengths on the simulated trees used here ended up being very short, so the high rate of success is still a good sign. \n",
    "\n",
    "This is also promising because it could be easily extended beyond four taxa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVDquartets inference on same data\n",
    "\n",
    "The loop below makes a bunch of quartet decisions on the same set of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenindexlist = []\n",
    "for w in range(1001,2001):\n",
    "    sequencedata = \"tree_seqs/test\" + str(w) + \".dat\"\n",
    "    # read in data\n",
    "\n",
    "    fname = sequencedata\n",
    "    with open(fname) as f:\n",
    "        sequences = f.readlines()\n",
    "\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "\n",
    "    sequences = [x.strip() for x in sequences] \n",
    "    sequences.pop(0)\n",
    "\n",
    "    # get sequences  and identify quintet taxa\n",
    "    names = [sequences[i][0:10].strip(\" \") for i in range(len(sequences))]\n",
    "    iso_sequences = [sequences[i][10:].strip(\" \") for i in range(len(sequences))]\n",
    "    \n",
    "    # so we're only testing one possible quartet per tree... Easy to expand this to test every quintet per tree\n",
    "    interestednames = [\"t1\",\"t2\",\"t3\",\"t4\"]\n",
    "    taxa_ids = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in interestednames]]))\n",
    "    \n",
    "    #taxa_ids = [3,2,8,9]\n",
    "    #fourtaxa = [names[i] for i in taxa_ids]\n",
    "\n",
    "    tempobj = [iso_sequences[i] for i in taxa_ids]\n",
    "\n",
    "    # eliminate non-snps\n",
    "\n",
    "    ind_samples = []\n",
    "    for i in range(len(tempobj[0])):\n",
    "        currentbase = ([tempobj[q][i] for q in range(len(tempobj))])\n",
    "        if (len(set(currentbase)) > 1):\n",
    "            ind_samples.append(currentbase)\n",
    "    ind_samples_reset = ind_samples\n",
    "\n",
    "    # separate sequences by fifth taxon\n",
    "\n",
    "    ind_samples = np.array(ind_samples_reset)\n",
    "    ind_samples = np.where(ind_samples=='A',0,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='C',1,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='G',2,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='T',3,ind_samples)\n",
    "    ind_samples = ind_samples.astype(int)\n",
    "    \n",
    "    possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "    # get the matrices\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "    # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    arr0123 = ind_samples\n",
    "    for i in range(len(arr0123)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[arr0123[i][0],arr0123[i][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[arr0123[i][2],arr0123[i][3]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    " \n",
    "\n",
    "    fullmat0213 = np.zeros(shape=(16,16))\n",
    "    arr0213 = ind_samples[:,possible_configs[1]]\n",
    "    for i in range(len(arr0213)):\n",
    "        # get row number \n",
    "        rownum = int(indexmat[arr0213[i][0:2][0],arr0213[i][0:2][1]])\n",
    "        # get col number\n",
    "        colnum = int(indexmat[arr0213[i][2:4][0],arr0213[i][2:4][1]])\n",
    "        fullmat0213[rownum,colnum] = fullmat0213[rownum,colnum] + 1\n",
    "\n",
    "    fullmat0312 = np.zeros(shape=(16,16))\n",
    "    arr0312 = ind_samples[:,possible_configs[2]]\n",
    "    for i in range(len(arr0312)):\n",
    "        # get row number \n",
    "        rownum = int(indexmat[arr0312[i][0:2][0],arr0312[i][0:2][1]])\n",
    "        # get col number\n",
    "        colnum = int(indexmat[arr0312[i][2:4][0],arr0312[i][2:4][1]])\n",
    "        fullmat0312[rownum,colnum] = fullmat0312[rownum,colnum] + 1\n",
    "    #score the matrices here\n",
    "    scores = [math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0123)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0213)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0312)[1][10:15])))]\n",
    "    #choose best scoring matrix\n",
    "    min_index, min_value = min(enumerate(scores), key=itemgetter(1))\n",
    "    chosenindex = np.array([0,0,0])\n",
    "    chosenindex[min_index] = 1\n",
    "    chosenindexlist.append(chosenindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tally up the correctly inferred quartets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "truequarts = [labels[i] for i in range(1000,2000)]\n",
    "tally = 0\n",
    "for w in range(len(truequarts)):\n",
    "    if (sum(truequarts[w] == chosenindexlist[w]) == 3):\n",
    "        tally = tally + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, get the percent correct under SVDquartets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally / 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 93.5 percent of quartets inferred by SVDquartets are correct, although I won't rule out the possibility that I'm doing the scoring incorrectly.\n",
    "\n",
    "The softmax model had the benefit of being tailored specifically to the simulated data and making predictions on data generated under the same model. SVDquartets quartet selection performs pretty well regardless, which we can't yet say for softmax or a similar machine learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
