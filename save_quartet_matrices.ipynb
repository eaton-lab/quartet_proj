{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import re\n",
    "import random\n",
    "from itertools import compress\n",
    "import itertools\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patrick's function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_quartet_matrices(snpsfile,mapfile,outputfile):\n",
    "    \n",
    "    # read in snps\n",
    "    fname = snpsfile\n",
    "    with open(fname) as f:\n",
    "        snps = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    snps = [x.strip() for x in snps] \n",
    "    snps.pop(0)\n",
    "    \n",
    "    #read in map\n",
    "    fname = mapfile\n",
    "    with open(fname) as f:\n",
    "        snpmap = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    snpmap = [x.strip() for x in snpmap] \n",
    "    snpmap = [i.split('\\t') for i in snpmap]\n",
    "    snpmap = np.array(snpmap)\n",
    "    # get rid of inner column, convert to int\n",
    "    reducedmap = snpmap[:,[0,2,3]].astype(int)\n",
    "    \n",
    "    # save names by themselves and make list of corresponding integers\n",
    "    names = [snps[i][0:27].replace(\" \", \"\") for i in range(len(snps))]\n",
    "    namevals = range(len(names))\n",
    "    #namealias = dict(zip(namevals, names))\n",
    "    \n",
    "    # make snp seq object without names\n",
    "    full_snp_seqs = [snps[i][27:] for i in range(len(snps))]\n",
    "    \n",
    "    # Get an array of single base from each locus\n",
    "    ind_samples = []\n",
    "    for p in range(int(snpmap[:,0][-1])):\n",
    "        index = p+1\n",
    "        # get the characters in snpseqs that are part of that locus\n",
    "        which_bases = reducedmap[(reducedmap[:,0] == index),2]\n",
    "        snps_at_locus = [full_snp_seqs[i][(which_bases[0]-1):which_bases[-1]] for i in range(len(snps))]\n",
    "\n",
    "        # exclude species that have bad reads\n",
    "        # [True in [snps_at_locus[p][i] not in ['A','G','C','T'] for i in range(len(snps_at_locus[p]))] for p in range(len(snps_at_locus))]\n",
    "\n",
    "        # pick a random base from each locus\n",
    "        randombase = random.randint(0, (len(snps_at_locus[0])-1))\n",
    "        selectedbases = [snps_at_locus[i][randombase] for i in range(len(snps_at_locus))]\n",
    "        ind_samples.append(selectedbases)\n",
    "        #fil = [i in ['A','G','C','T'] for i in selectedbases]\n",
    "        #np.array([list(compress(namevals,fil)),list(compress(selectedbases, fil))])\n",
    "\n",
    "    ind_samples = np.array(ind_samples)\n",
    "    \n",
    "    # get all quartets to be evaluated\n",
    "    # ...should try to not create this as a list yet...\n",
    "    all_quartets = list(itertools.combinations(namevals,4))\n",
    "\n",
    "    # these are the possible arrangements of each quartets\n",
    "    possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "\n",
    "    # fill this with selected quartet\n",
    "    quartet_decisions = []\n",
    "\n",
    "\n",
    "    all_matrices = h5py.File(outputfile, \"w\")\n",
    "    num_quartets = len(all_quartets)\n",
    "    for q in range(num_quartets):\n",
    "\n",
    "        #fil = [i in ['A','G','C','T'] for i in ind_samples[all_quartets[0],0:10]]\n",
    "\n",
    "        # boolean list of loci that are each a subset of AGCT\n",
    "        fil = [( len(set(ind_samples[i,all_quartets[q]]) | {'A','G','C','T'}) == 4) for i in range(len(ind_samples))]\n",
    "\n",
    "        # array of informative loci\n",
    "        finalsnps = ind_samples[:,all_quartets[q]][fil]\n",
    "\n",
    "        # substitute integer values for AGCT\n",
    "        finalsnps = np.where(finalsnps=='A',0,finalsnps)\n",
    "        finalsnps = np.where(finalsnps=='C',1,finalsnps)\n",
    "        finalsnps = np.where(finalsnps=='G',2,finalsnps)\n",
    "        finalsnps = np.where(finalsnps=='T',3,finalsnps)\n",
    "        finalsnps = finalsnps.astype(int)\n",
    "\n",
    "        # make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "        indexmat = np.array(range(16))\n",
    "        indexmat.shape=(4,4)\n",
    "\n",
    "        # make 16x16 matrix of zeroes\n",
    "        # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "        # not good use of space\n",
    "        fullmat0123 = np.zeros(shape=(16,16))\n",
    "        arr0123 = finalsnps[:,possible_configs[0]]\n",
    "        for i in range(len(arr0123)):\n",
    "            # get row number \n",
    "            rownum = int(indexmat[arr0123[i][0:2][0],arr0123[i][0:2][1]])\n",
    "            # get col number\n",
    "            colnum = int(indexmat[arr0123[i][2:4][0],arr0123[i][2:4][1]])\n",
    "            fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "\n",
    "        fullmat0213 = np.zeros(shape=(16,16))\n",
    "        arr0213 = finalsnps[:,possible_configs[1]]\n",
    "        for i in range(len(arr0213)):\n",
    "            # get row number \n",
    "            rownum = int(indexmat[arr0213[i][0:2][0],arr0213[i][0:2][1]])\n",
    "            # get col number\n",
    "            colnum = int(indexmat[arr0213[i][2:4][0],arr0213[i][2:4][1]])\n",
    "            fullmat0213[rownum,colnum] = fullmat0213[rownum,colnum] + 1\n",
    "\n",
    "        fullmat0312 = np.zeros(shape=(16,16))\n",
    "        arr0312 = finalsnps[:,possible_configs[2]]\n",
    "        for i in range(len(arr0312)):\n",
    "            # get row number \n",
    "            rownum = int(indexmat[arr0312[i][0:2][0],arr0312[i][0:2][1]])\n",
    "            # get col number\n",
    "            colnum = int(indexmat[arr0312[i][2:4][0],arr0312[i][2:4][1]])\n",
    "            fullmat0312[rownum,colnum] = fullmat0312[rownum,colnum] + 1\n",
    "        # # get the scores\n",
    "        # scores = [math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0123)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0213)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0312)[1][10:15])))]\n",
    "\n",
    "        # # get index of minimum score, via <https://stackoverflow.com/questions/2474015/getting-the-index-of-the-returned-max-or-min-item-using-max-min-on-a-list>\n",
    "        # min_index, min_value = min(enumerate(scores), key=itemgetter(1))\n",
    "        # quartet_decisions.append([names[p] for p in [all_quartets[q][i] for i in possible_configs[min_index]]])\n",
    "\n",
    "        # save datasets in HDF5\n",
    "        dset1 = all_matrices.create_dataset(('_'.join([str(i) for i in all_quartets[q]]) + '/0123'), data=fullmat0123,chunks=True)\n",
    "        dset2 = all_matrices.create_dataset(('_'.join([str(i) for i in all_quartets[q]]) + '/0213'), data=fullmat0213,chunks=True)\n",
    "        dset3 = all_matrices.create_dataset(('_'.join([str(i) for i in all_quartets[q]]) + '/0312'), data=fullmat0312,chunks=True)\n",
    "        \n",
    "        # write out progress\n",
    "        sys.stdout.write('\\r'+\"{0:.2f}\".format(float(q)*100/float(num_quartets))+'%')\n",
    "    \n",
    "    all_matrices.close()\n",
    "    sys.stdout.write('\\r'+'Done.')\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.1 loop, best of 1: 5min 6s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "## time to run this one time with no replicates per run\n",
    "random.seed(12345)\n",
    "save_quartet_matrices(\n",
    "    snpsfile = \"analysis-ipyrad/min4_outfiles/min4.snps.phy\",\n",
    "    mapfile = \"analysis-ipyrad/min4_outfiles/min4.snps.map\",\n",
    "    outputfile = \"all_matrices.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deren's annotated functions \n",
    "This is similar to how tetrad implements it, but with some of the fancier complications removed, written here to make it a bit more clear. Some key differences from tetrad include: \n",
    "\n",
    "+ heterozygous sites are not randomly resolved. \n",
    "+ here and in your code a single SNP is randomly sampled from each locus before looking at any of the quartets. In tetrad a single SNP is randomly sampled from each locus **independently for each quartet**, since a SNP in one quartet is not necessarily a SNP in a different quartet. This is a somewhat critical thing that maximizes the amount of information available for every given quartet. This is done in tetrad by storing locus information in the 'spans' array. It makes the tetrad code a little hard to follow, however, so I'm skipping it here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_snps(snpsfile):\n",
    "    \"\"\"Read in the snps file and store as a numpy array\"\"\"\n",
    "    ## the SNPs file can be efficiently stored as a uint8 array,\n",
    "    ## see '_init_seqarray()` function in tetrad2\n",
    "    with open(snpsfile) as infile:\n",
    "        ## parse first line to get size of the dataset\n",
    "        line = infile.readline().strip().split()\n",
    "        ntax, nbp = [int(i) for i in line]\n",
    "        \n",
    "        ## make an empty array of this size \n",
    "        tmpseq = np.zeros((ntax, nbp), dtype=np.uint8)\n",
    "        \n",
    "        ## fill tmpseq with data from disk. We already read\n",
    "        ## the first line so this will continue reading from\n",
    "        ## the second line, one line at a time.\n",
    "        for idx, line in enumerate(infile):\n",
    "            ## separate name from seq \n",
    "            _, seq = line.split()\n",
    "            ## store it as the right datatype\n",
    "            tmpseq[idx] = np.array(list(seq)).view(np.uint8)\n",
    "                               \n",
    "        ## convert '-' characters into \"Ns\". We'll skip for now \n",
    "        ## but tetrad also randomly resolves heterozygous SNPs\n",
    "        ## they will just be ignored here\n",
    "        tmpseq[tmpseq == 45] == 78\n",
    "        ## simple indexing of ACGT\n",
    "        tmpseq[tmpseq == 65] = 0\n",
    "        tmpseq[tmpseq == 67] = 1\n",
    "        tmpseq[tmpseq == 71] = 2\n",
    "        tmpseq[tmpseq == 84] = 3\n",
    "    return tmpseq\n",
    "\n",
    "\n",
    "def load_map(mapfile):\n",
    "    \"\"\"Read in the mapfile and store as a numpy array\"\"\"\n",
    "    ## the MAPfile can be efficiently loaded using numpy\n",
    "    ## b/c it is already a tsv file, basically.\n",
    "    with open(mapfile) as inmap:\n",
    "        ## use large dtype b/c numbers in this can be really high\n",
    "        ## we only need columns and 0 and 3\n",
    "        maparr = np.genfromtxt(inmap, dtype=np.uint64)[:, [0, 3]]\n",
    "        ## get a random SNP from each loc\n",
    "        nloci = maparr[:, 0].max()\n",
    "        ## random sampling here instead of later (see notes)\n",
    "        ranloc = np.zeros(nloci, dtype=np.uint64)\n",
    "        for idx in xrange(1, nloci):\n",
    "            ranloc[idx] = np.random.choice(maparr[maparr[:, 0]==idx, 1], 1)\n",
    "    return ranloc\n",
    "\n",
    "\n",
    "def save_qrt_arr(snpsfile, mapfile, outputfile):\n",
    "    \"\"\"Build invariants matrix and write to an HDF5 database\"\"\"\n",
    "    tmpseq = load_snps(snpsfile)\n",
    "    ranloc = load_map(mapfile)\n",
    "    \n",
    "    ## not memory efficient for big jobs, tetrad stores the full\n",
    "    ## array of quartets in a hdf5 db and grabs it in chunks.\n",
    "    qrts = np.array(list(itertools.combinations(range(10), 4)))\n",
    "    \n",
    "    ## iterate over quartets getting results\n",
    "    invars = np.zeros((qrts.shape[0], 3, 16, 16), dtype=np.uint32)\n",
    "    for qidx in xrange(qrts.shape[0]):\n",
    "        sidx = qrts[qidx]\n",
    "        seqs = tmpseq[sidx]\n",
    "        \n",
    "        ## fill in the invariants\n",
    "        for rsite in ranloc:\n",
    "            v = seqs[:, rsite]\n",
    "            ## skip if not only ACTG or if invariant\n",
    "            if all(v < 4):\n",
    "                if not all(v==v[0]):\n",
    "                    invars[qidx, 0, (4*v[0])+v[1], (4*v[2])+v[3]] += 1\n",
    "\n",
    "        x = 0\n",
    "        for y in (0, 4, 8, 12):\n",
    "            for z in (0, 4, 8, 12):\n",
    "                oarr = invars[qidx, 0, x]\n",
    "                invars[qidx, 1, y:y+4, z:z+4] = oarr.reshape(4, 4)\n",
    "                invars[qidx, 2, y:y+4, z:z+4] = oarr.reshape(4, 4).T\n",
    "                x += 1\n",
    "\n",
    "    ## write invars array to hdf5\n",
    "    with h5py.File(outputfile, 'w') as outf:\n",
    "        outf.create_dataset(\"invariants\", data=invars)\n",
    "    \n",
    "    ## also return the array to look at \n",
    "    return invars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 50.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 \n",
    "## test it\n",
    "np.random.seed(12345)\n",
    "save_qrt_arr(\n",
    "    snpsfile=\"analysis-ipyrad/min4_outfiles/min4.snps.phy\",\n",
    "    mapfile=\"analysis-ipyrad/min4_outfiles/min4.snps.map\",\n",
    "    outputfile=\"invariants.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing results...\n",
    "Great job! It looks like your invariants are really similar to what I calculated. The difference might just be the different random seed generators we used (random vs. np.random). Your implementation runs pretty fast too, in about 3.5 minutes while my implementation here is about 40 seconds. The tetrad implementation uses JIT compiled functions, which allows it to run much faster (~5 seconds; see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  94 341 171  10   1   0   1  30   1   6   1  19   0   0   2]\n",
      " [ 20  24   1   3   1  25   0   0   0   0   1   0   0   1   0   0]\n",
      " [ 81   0  42   2   0   0   0   0   9   0  61   1   0   0   0   0]\n",
      " [ 47   1   0   9   0   0   0   0   0   0   1   0   0   1   0  21]\n",
      " [  9   1   0   0   9  42   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1  20   0   0 110   0  75 305   0  11   1   0   0  72   0   4]\n",
      " [  0   0   0   0   1  28   6   2   0   0  13   0   0   0   0   0]\n",
      " [  0   0   0   0   1 116   3  39   0   0   0   0   0   4   0  37]\n",
      " [ 37   0   2   1   1   0   0   0  44   0  80   1   0   0   0   0]\n",
      " [  0   0   0   0   0  13   0   1   0   7  17   0   0   0   1   0]\n",
      " [  4   2  65   1   0   0   9   1 285  89   0  91   0   0  19   0]\n",
      " [  1   0   0   0   0   0   0   0   2   0  29   9   0   0   0   3]\n",
      " [ 16   0   0   0   0   2   0   0   0   0   0   0  23   2   5  33]\n",
      " [  0   0   0   0   0  66   1   4   0   0   0   0   1  36   1  73]\n",
      " [  0   0   0   0   0   0   0   0   0   0  38   1   1   1  18  20]\n",
      " [  2   0   0  13   1   4   1  44   0   0   1  11 168 333  92   0]]\n"
     ]
    }
   ],
   "source": [
    "## show the 0123 matrix from 'save_qrt_arr()`\n",
    "with h5py.File(\"invariants.hdf5\") as io5:\n",
    "    arr = io5[\"invariants\"][0, 0, :]\n",
    "    print arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  91 326 174   5   1   0   1  33   0   8   0  14   0   0   1]\n",
      " [ 16  28   1   3   3  27   0   1   0   0   0   0   0   1   0   0]\n",
      " [ 84   1  43   2   0   0   0   0   6   0  64   1   0   0   0   0]\n",
      " [ 39   0   0  16   0   0   0   0   0   0   0   0   0   0   0  19]\n",
      " [ 10   0   0   0   3  48   1   1   0   0   0   0   0   0   0   0]\n",
      " [  1  21   0   2 104   0  79 285   0  15   1   1   1  74   1   4]\n",
      " [  0   0   0   0   0  25   7   3   0   2   6   0   0   0   0   0]\n",
      " [  0   0   0   0   0 105   2  35   0   0   0   0   0   4   1  39]\n",
      " [ 33   0   4   1   1   0   0   0  40   0  98   2   0   0   0   0]\n",
      " [  0   0   0   0   0  10   1   0   1  11  19   0   0   0   0   0]\n",
      " [  8   0  66   1   0   0  14   0 300  67   0  99   0   0  24   0]\n",
      " [  0   0   1   0   0   0   0   0   2   0  36   7   0   0   1  10]\n",
      " [ 14   0   0   1   0   0   0   0   1   0   0   0  12   2   1  31]\n",
      " [  0   0   0   0   0  65   1   3   0   0   0   0   0  40   1  67]\n",
      " [  0   0   0   0   0   0   0   0   0   0  30   0   0   0  20  15]\n",
      " [  1   1   0  14   0   1   0  35   0   0   1   8 197 325  93   0]]\n"
     ]
    }
   ],
   "source": [
    "## show the 0123 matrix from 'save_quartet_matrices()'\n",
    "with h5py.File(\"all_matrices.hdf5\") as io5:\n",
    "    arr = io5[\"0_1_2_3\"][\"0123\"][:]\n",
    "\n",
    "## clear out the constants (e.g., AAAA)\n",
    "arr[0,0] = 0\n",
    "arr[5,5] = 0\n",
    "arr[10,10] = 0\n",
    "arr[15,15] = 0\n",
    "\n",
    "## show 0123 matrix\n",
    "print arr.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tetrad implementation\n",
    "Because tetrad resolves ambiguous sites and randomly samples every quartet for SNPs that are segregating in the quartet, it recovers a lot more SNPs than the previous two implementations. You can see that I use the `-r2` option in the `timeit()` function below to run two repliates of the tetrad analysis, this is because the first one will have a delay caused the time spent just-in-time compiling the functions (JIT), and so the second run is faster. There is also some overhead in this approach of setting up the parallel client, even though I run it on only one core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.12\n"
     ]
    }
   ],
   "source": [
    "import ipyrad.analysis as ipa\n",
    "import ipyparallel as ipp\n",
    "print ipa.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading seq array [13 taxa x 173131 bp]\n",
      "max unlinked SNPs per quartet (nloci): 39634\n",
      "inferring 715 quartet tree sets\n",
      "host compute node: [1 cores] on sacra\n",
      "[####################] 100% generating q-sets | 0:00:00 |  \n",
      "[####################] 100% initial tree      | 0:00:01 |  \n",
      "[####################] 100% calculating stats | 0:00:00 |  \n",
      "loading seq array [13 taxa x 173131 bp]\n",
      "max unlinked SNPs per quartet (nloci): 39634\n",
      "inferring 715 quartet tree sets\n",
      "host compute node: [1 cores] on sacra\n",
      "[####################] 100% generating q-sets | 0:00:00 |  \n",
      "[####################] 100% initial tree      | 0:00:01 |  \n",
      "[####################] 100% calculating stats | 0:00:00 |  \n",
      "1 loop, best of 2: 7.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r2 -n1\n",
    "\n",
    "## initiate an ipyrad object\n",
    "tet = ipa.tetrad(\n",
    "    name='test2', \n",
    "    data=\"analysis-ipyrad/min4_outfiles/min4.snps.phy\",\n",
    "    mapfile=\"analysis-ipyrad/min4_outfiles/min4.snps.map\",\n",
    "    save_invariants=True,\n",
    "    )\n",
    "\n",
    "## use an ipcluster instance with only 1 core\n",
    "ipyclient = ipp.Client(profile='alt')\n",
    "tet.run(force=True, quiet=False, ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 150 559 239  18   2   0   2  59   1  15   0  25   0   0   0]\n",
      " [ 43  25   1   2   1  42   0   1   0   0   1   0   0   1   0   0]\n",
      " [156   1  72   2   0   0   0   0  12   0 110   2   0   0   1   0]\n",
      " [ 65   1   0  15   0   0   0   1   0   0   0   0   0   0   1  29]\n",
      " [ 18   0   0   1   8  71   1   3   0   0   0   0   0   0   0   0]\n",
      " [  1  34   1   3 166   0 115 485   0  19   3   2   2 112   1   9]\n",
      " [  0   0   0   0   0  46  12   2   0   1  11   0   0   0   0   0]\n",
      " [  0   1   0   0   3 207   6  74   0   0   0   0   0   8   1  66]\n",
      " [ 49   0   8   3   1   0   0   0  51   2 176   2   0   0   1   0]\n",
      " [  0   0   0   0   0  20   0   2   2  11  30   0   0   0   0   0]\n",
      " [  8   0  98   1   0   2  15   0 501 121   0 136   0   1  39   0]\n",
      " [  0   0   2   0   0   0   0   1   3   2  68  12   0   1   2  15]\n",
      " [ 46   0   0   1   0   3   0   0   0   0   0   0  25   1   3  49]\n",
      " [  0   0   0   0   0 130   0   7   0   0   0   0   1  54   2 109]\n",
      " [  0   0   1   0   0   1   0   0   2   0  40   0   1   2  28  31]\n",
      " [  0   1   0  17   1   5   0  64   0   0   3  17 261 526 133   0]]\n"
     ]
    }
   ],
   "source": [
    "## look at the invariants array from tetrad\n",
    "with h5py.File(\"analysis-tetrad/test.output.h5\") as io5:\n",
    "    arr = io5['invariants/boot0'][0, :]\n",
    "    print arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
